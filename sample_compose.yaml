services:
  bot:
    image: shashibot:latest
    env_file:
      - .env
    # environment:
        # LLM_API_BASEURL: "http://gemini-openai-proxy:8000/v1"
        # LLM_API_KEY: "NONE"

  local_llm:
    image: shashillm:latest
    volumes:
      - ../models:/models
    stdin_open: false # docker run -i
    tty: false        # docker run -t
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: [ "--model","./models/model.gguf","--n_gpu_layers", "24","--chat_format","chatml"]

  gemini-openai-proxy:
      image: ghcr.io/zuisong/gemini-openai-proxy:node

  registercommands:
    image: shashibot:latest
    env_file:
      - .env
    command: ["registercommands.js"]
